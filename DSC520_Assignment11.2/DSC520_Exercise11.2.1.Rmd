---
title: "DSC520 Week11-12 Exercise 11.2.1"
author: "Anjani Bonda"
date: March 4th 2022
Exercise: Introduction to Machine Learning
output:
  pdf_document: default
  word_document: default
  html_document: default
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

```{r}
# Load the packages
library(caTools)
library(ggplot2)
setwd("/Users/anjanibonda/DSC520/dsc520")
# Load the binary classifier dataset to dataframe
binary_df <- read.csv("data/binary-classifier-data.csv")
# Examine the structure
str(binary_df)
# Check sample rows
head(binary_df)
# Load the trinary classifer dataset to dataframe
trinary_df <- read.csv("data/trinary-classifier-data.csv")
# Exampine the structure
str(trinary_df)
# Check sample rows
head(trinary_df)
# i. Plot the data from each dataset using scatter plot
ggplot(binary_df, aes(x=binary_df$x, y=binary_df$y)) + geom_point(aes(color = binary_df$label))
ggplot(trinary_df, aes(x=trinary_df$x, y=trinary_df$y)) + geom_point(aes(color = trinary_df$label))
# Normalization of binary_df
normalize <- function(x) { return ((x - min(x)) / (max(x) - min(x))) }
binary_df.n = as.data.frame(lapply(binary_df[,2:3], normalize))
binary_df.n = as.data.frame(lapply(binary_df[,2:3], normalize))
set.seed(123)
# Random sample of 70% of data
dat.d <- sample(1:nrow(binary_df.n), size = nrow(binary_df.n)*0.7, replace = FALSE)
# Create test and train datasets
train.binary_df <- binary_df[dat.d,]
test.binary_df <- binary_df[-dat.d,]
# Create separate dataframe for label feature
train.binary_df_label <- binary_df[dat.d,1]
test.binary_df_label <- binary_df[-dat.d,1]
# Find no. of observations
NROW(train.binary_df)
# From above, we have 700 observations in our training dataset. The square root of 700 is about 26.45. 
# Therefore, we'll create 2 models.One with 'K' value 26 and other with 'K' value 27
library(class)
knn.binary_df.1 <- knn(train=train.binary_df, test=test.binary_df, cl=train.binary_df_label, k=1)
# Calculate accuracy of the models
# Caculate the proportion of correct classification for k=32,33
ACC.binary_df.1 <- 100*sum(test.binary_df_label == knn.binary_df.1)/NROW(test.binary_df_label)
ACC.binary_df.1
# Accuracy is 98.22
# Check prediction against actual value in tabular form for k=32
table(knn.binary_df.1, test.binary_df_label)
# Use confusion matrix to calculate the accuracy.
library(caret)
confusionMatrix(table(knn.binary_df.1, test.binary_df_label))
# Normalization of trinary_df
normalize <- function(x) { return ((x - min(x)) / (max(x) - min(x))) }
trinary_df.n = as.data.frame(lapply(trinary_df[,2:3], normalize))
trinary_df.n = as.data.frame(lapply(trinary_df[,2:3], normalize))
set.seed(123)
# Random sample of 70% of data
dat.d <- sample(1:nrow(trinary_df.n), size = nrow(trinary_df.n)*0.7, replace = FALSE)
# Create test and train datasets
train.trinary_df <- trinary_df[dat.d,]
test.trinary_df <- trinary_df[-dat.d,]
# Create separate dataframe for label feature
train.trinary_df_label <- trinary_df[dat.d,1]
test.trinary_df_label <- trinary_df[-dat.d,1]
# Find no. of observations
NROW(train.trinary_df)
library(class)
knn.trinary_df.1 <- knn(train=train.trinary_df, test=test.trinary_df, cl=train.trinary_df_label, k=1)
# Calculate accuracy of the models
# Caculate the proportion of correct classification for k=32,33
ACC.trinary_df.1 <- 100*sum(test.trinary_df_label == knn.trinary_df.1)/NROW(test.trinary_df_label)
ACC.trinary_df.1
# Accuracy is 95.75
# Check prediction against actual value in tabular form for k=32
table(knn.trinary_df.1, test.trinary_df_label)
# Use confusion matrix to calculate the accuracy.
library(caret)
confusionMatrix(table(knn.trinary_df.1, test.trinary_df_label))
# ii Fit a k nearest neighborsâ€™ model for each dataset for k=3, k=5, k=10, k=15, k=20, and k=25. Compute the accuracy of the resulting models for each value of k. Plot the results in a graph where the x-axis is the different values of k and the y-axis is the accuracy of the model.
# Accuracy level of binary dataset
j <- 1
k.optm <- 1
for (i in c(3,5,10,15,20,25)){
  knn.mod <- knn(train=train.binary_df, test=test.binary_df, cl=train.binary_df_label, k=i)
  k.optm[i] <- 100 * sum(test.binary_df_label == knn.mod)/NROW(test.binary_df_label)
  k <- i
  j <- j + 1
  cat(k,'=',k.optm[i],'')}
# Accuracy Plot
plot(k.optm, type="b",xlab="K-value",ylab="Accuracy of Binary Dataset")
# Accuracy level of trinary dataset
j <- 1
k.optm <- 1
for (i in c(3,5,10,15,20,25)){
  knn.mod <- knn(train=train.trinary_df, test=test.trinary_df, cl=train.trinary_df_label, k=i)
  k.optm[i] <- 100 * sum(test.trinary_df_label == knn.mod)/NROW(test.trinary_df_label)
  k <- i
  j <- j + 1
  cat(k,'=',k.optm[i],'')}
# Accuracy Plot
plot(k.optm, type="b",xlab="K-value",ylab="Accuracy of Trinary Dataset")
# i. Looking back at the plots of the data, do you think a linear classifier would work well on these datasets?
x1=binary_df[2]
x2=binary_df[3]
y <- sign(3 * x1 - 4 * x2 - 1)
y[y == -1] <- 0
df <- cbind.data.frame(y,x1,x2)
names(df)[1] <- 'y'
names(df)[2] <- 'x1'
names(df)[3] <- 'x2'
mdl <- glm(y ~ . , data=df,family = binomial)
slope <- coef(mdl)[2]/(-coef(mdl)[3])
intercept <- coef(mdl)[1]/(-coef(mdl)[3])
library(lattice)
xyplot(x2 ~ x1,data=df, groups=y,panel=function(...){
  panel.xyplot(...)
  panel.abline(intercept, slope)
  panel.grid(...)
})
x1= trinary_df[2]
x2= trinary_df[3]
y <- sign(3 * x1 - 4 * x2 - 1)
y[y == -1] <- 0
df <- cbind.data.frame(y,x1,x2)
names(df)[1] <- 'y'
names(df)[2] <- 'x1'
names(df)[3] <- 'x2'
mdl <- glm(y ~ . , data=df,family = binomial)
slope <- coef(mdl)[2]/(-coef(mdl)[3])
intercept <- coef(mdl)[1]/(-coef(mdl)[3])
library(lattice)
xyplot(x2 ~ x1,data=df, groups=y,panel=function(...){
  panel.xyplot(...)
  panel.abline(intercept, slope)
  panel.grid(...)
})
# Looking at the plots, I think that the linear classifer would work well on binary dataset but not on trinary
# dataset
# ii. How does the accuracy of your logistic regression classifier from last week compare?  Why is the accuracy # different between these two methods?

## The accuracy of logistic regression model was 67% but the accuracy of knn model is 98% of binary dataset.
## The difference in accuracy is due to the non-linearness of the data in the input datasets.
## KNN fits good for the non-linear dataset and hence it is more suitable model in our case.
```

