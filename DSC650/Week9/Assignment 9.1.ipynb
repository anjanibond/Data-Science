{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Assignment 9.1\n",
    "\n",
    "<br>Name: Kesav Adithya Venkidusamy\n",
    "<br>Course: DSC650 - Big Data\n",
    "<br>Instructor: Amirfarrokh Iranitalab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import shutil\n",
    "import json\n",
    "from pathlib import Path\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "from kafka import KafkaProducer, KafkaAdminClient\n",
    "from kafka.admin.new_topic import NewTopic\n",
    "from kafka.errors import TopicAlreadyExistsError\n",
    "from kafka import KafkaConsumer\n",
    "\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.streaming import StreamingContext\n",
    "from pyspark import SparkConf\n",
    "from pyspark.sql.functions import window, from_json, col\n",
    "from pyspark.sql.types import StringType, TimestampType, DoubleType, StructField, StructType\n",
    "from pyspark.sql.functions import udf\n",
    "\n",
    "current_dir = Path(os.getcwd()).absolute()\n",
    "checkpoint_dir = current_dir.joinpath('checkpoints')\n",
    "locations_checkpoint_dir = checkpoint_dir.joinpath('locations')\n",
    "accelerations_checkpoint_dir = checkpoint_dir.joinpath('accelerations')\n",
    "\n",
    "if locations_checkpoint_dir.exists():\n",
    "    shutil.rmtree(locations_checkpoint_dir)\n",
    "    \n",
    "if accelerations_checkpoint_dir.exists():\n",
    "    shutil.rmtree(accelerations_checkpoint_dir)\n",
    "\n",
    "locations_checkpoint_dir.mkdir(parents=True, exist_ok=True)\n",
    "accelerations_checkpoint_dir.mkdir(parents=True, exist_ok=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Configuration Parameters "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'bootstrap_servers': ['kafka.kafka.svc.cluster.local:9092'],\n",
       " 'first_name': 'KesavAdithya',\n",
       " 'last_name': 'Venkidusamy',\n",
       " 'client_id': 'VenkidusamyKesavAdithya',\n",
       " 'topic_prefix': 'VenkidusamyKesavAdithya',\n",
       " 'locations_topic': 'VenkidusamyKesavAdithya-locations',\n",
       " 'accelerations_topic': 'VenkidusamyKesavAdithya-accelerations',\n",
       " 'simple_topic': 'VenkidusamyKesavAdithya-simple'}"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "config = dict(\n",
    "    bootstrap_servers=['kafka.kafka.svc.cluster.local:9092'],\n",
    "    first_name='KesavAdithya',\n",
    "    last_name='Venkidusamy'\n",
    ")\n",
    "\n",
    "config['client_id'] = '{}{}'.format(\n",
    "    config['last_name'], \n",
    "    config['first_name']\n",
    ")\n",
    "config['topic_prefix'] = '{}{}'.format(\n",
    "    config['last_name'], \n",
    "    config['first_name']\n",
    ")\n",
    "\n",
    "config['locations_topic'] = '{}-locations'.format(config['topic_prefix'])\n",
    "config['accelerations_topic'] = '{}-accelerations'.format(config['topic_prefix'])\n",
    "config['simple_topic'] = '{}-simple'.format(config['topic_prefix'])\n",
    "\n",
    "config"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create Topic Utility Function\n",
    "\n",
    "The `create_kafka_topic` helps create a Kafka topic based on your configuration settings.  For instance, if your first name is *John* and your last name is *Doe*, `create_kafka_topic('locations')` will create a topic with the name `DoeJohn-locations`.  The function will not create the topic if it already exists. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Topic \"VenkidusamyKesavAdithya-simple\" already exists\n"
     ]
    }
   ],
   "source": [
    "def create_kafka_topic(topic_name, config=config, num_partitions=1, replication_factor=1):\n",
    "    bootstrap_servers = config['bootstrap_servers']\n",
    "    client_id = config['client_id']\n",
    "    topic_prefix = config['topic_prefix']\n",
    "    name = '{}-{}'.format(topic_prefix, topic_name)\n",
    "    \n",
    "    admin_client = KafkaAdminClient(\n",
    "        bootstrap_servers=bootstrap_servers, \n",
    "        client_id=client_id\n",
    "    )\n",
    "    \n",
    "    topic = NewTopic(\n",
    "        name=name,\n",
    "        num_partitions=num_partitions,\n",
    "        replication_factor=replication_factor\n",
    "    )\n",
    "\n",
    "    topic_list = [topic]\n",
    "    try:\n",
    "        admin_client.create_topics(new_topics=topic_list)\n",
    "        print('Created topic \"{}\"'.format(name))\n",
    "    except TopicAlreadyExistsError as e:\n",
    "        print('Topic \"{}\" already exists'.format(name))\n",
    "    \n",
    "create_kafka_topic('simple')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "spark = SparkSession\\\n",
    "    .builder\\\n",
    "    .appName(\"Assignment09\")\\\n",
    "    .getOrCreate()\n",
    "\n",
    "df_locations = spark \\\n",
    "  .readStream \\\n",
    "  .format(\"kafka\") \\\n",
    "  .option(\"kafka.bootstrap.servers\", \"kafka.kafka.svc.cluster.local:9092\") \\\n",
    "  .option(\"subscribe\", config['locations_topic']) \\\n",
    "  .load()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**TODO:** Create a data frame called `df_accelerations` that reads from the accelerations topic you published to in assignment 8.  In order to read data from this topic, make sure that you are running the notebook you created in assignment 8 that publishes acceleration and location data to the `LastnameFirstname-simple` topic. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_accelerations = spark \\\n",
    "  .readStream \\\n",
    "  .format(\"kafka\") \\\n",
    "  .option(\"kafka.bootstrap.servers\", \"kafka.kafka.svc.cluster.local:9092\") \\\n",
    "  .option(\"subscribe\", config['accelerations_topic']) \\\n",
    "  .load()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**TODO:** Create two streaming queries, `ds_locations` and `ds_accelerations` that publish to the `LastnameFirstname-simple` topic. See http://spark.apache.org/docs/latest/structured-streaming-programming-guide.html#starting-streaming-queries and http://spark.apache.org/docs/latest/structured-streaming-kafka-integration.html for more information. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "STOPPING STREAMING DATA\n"
     ]
    }
   ],
   "source": [
    "ds_locations = df_locations \\\n",
    "    .writeStream \\\n",
    "    .format(\"kafka\") \\\n",
    "    .option(\"kafka.bootstrap.servers\", \"kafka.kafka.svc.cluster.local:9092\") \\\n",
    "    .option(\"topic\", config['simple_topic']) \\\n",
    "    .option(\"checkpointLocation\", \"/tmp/venkidusamykesavadithya/checkpoint\") \\\n",
    "    .start()\n",
    "\n",
    "ds_accelerations = df_accelerations \\\n",
    "    .writeStream \\\n",
    "    .format(\"kafka\") \\\n",
    "    .option(\"kafka.bootstrap.servers\", \"kafka.kafka.svc.cluster.local:9092\") \\\n",
    "    .option(\"topic\", config['simple_topic']) \\\n",
    "    .option(\"checkpointLocation\", \"/tmp/venkidusamykesavadithya/checkpoint\") \\\n",
    "    .start()\n",
    "\n",
    "try:\n",
    "    ds_locations.awaitTermination()\n",
    "    ds_accelerations.awaitTermination()\n",
    "except KeyboardInterrupt:\n",
    "    print(\"STOPPING STREAMING DATA\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
